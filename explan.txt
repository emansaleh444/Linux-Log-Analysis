
I extracted the compressed file and inspected its structure using Linux tools such as head, tail, wc, and ls.
I identified the log format including IP address, timestamp, request method, URL, status code, and response size.
I performed log analysis using awk, sort, uniq, and bc to calculate statistics such as top IPs, most requested URLs, error rate, and peak traffic hour.
I also detected suspicious IPs based on high request counts.
Finally, I automated the analysis by creating a bash script that accepts the log file as input and generates a structured report automatically.
This workflow simulates real-world Data Engineering log processing tasks
